{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GDriveSpeechClient.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "caWWD6L_J0Ue"
      ],
      "private_outputs": true,
      "mount_file_id": "1npWnEkPx8Mu7YW2FqIuwnSqhBh9Meaxl",
      "authorship_tag": "ABX9TyMyVu0A/5WQmrn5YMeAtVA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtkns/dx451/blob/main/GDriveSpeechClient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "notes:\n",
        "\n",
        "to be set up in gallery with recording\n",
        "\n",
        "waiver on rights for research and artistic use\n",
        "\n",
        "replace nouns with images\n",
        "\n",
        "colors with color\n",
        "\n",
        "use text to speech for prompts\n",
        "\n",
        "ask for next prompt"
      ],
      "metadata": {
        "id": "MuXvX366OxBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Configuration"
      ],
      "metadata": {
        "id": "ORyqCFnsnN_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### you'll need to restart after running the next one, so run it first"
      ],
      "metadata": {
        "id": "qHPJXaxeEomI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-B1eBxcgDJw"
      },
      "outputs": [],
      "source": [
        "#Speech-to-text\n",
        "!pip install --upgrade google-cloud-speech\n",
        "\n",
        "#Text-to-speech\n",
        "!pip install gTTS\n",
        "\n",
        "#image search\n",
        "!pip install Google-Images-Search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### project settings"
      ],
      "metadata": {
        "id": "AifI5GgYnYMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##project settings\n",
        "\n",
        "#@markdown ###Google Cloud Project ID\n",
        "#@markdown * Should have 'Cloud Speech API' activated\n",
        "project_id = 'wtkns-214817' #@param {type:\"string\"}\n",
        "bucket_name = 'wtkns-store' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###Google Cloud Service Account name. \n",
        "#@markdown * Should have 'Cloud Speech Client' permissions\n",
        "#@markdown * will be of _username_@_projectname_.iam.gserviceaccount.com\n",
        "service_account_user_name = 'speechtt' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###this should be the folder where you want to store files \n",
        "content_name = 'honey' #@param {type:\"string\"}\n",
        "\n",
        "project_path = \"/content/drive/MyDrive/DX451/Rules/\" + content_name + \"/\"\n",
        "input_video_path = project_path + content_name + \".mkv\"\n",
        "output_file = project_path + content_name + \".output.mp4\"\n",
        "output_width = 800\n",
        "output_height = 600"
      ],
      "metadata": {
        "id": "ak8YZUNeGx-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to the google drive to store files"
      ],
      "metadata": {
        "id": "iBz9YOpO3XhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate with Google, requires interactive prompt"
      ],
      "metadata": {
        "id": "b54VTL5DxjXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate project user\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project {project_id}"
      ],
      "metadata": {
        "id": "QWwuI5DxxhW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "if not os.path.isdir(project_path):\n",
        "  os.makedirs(project_path)\n",
        "os.chdir(project_path)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "LfhZz850EO1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up source files"
      ],
      "metadata": {
        "id": "Frm2glyMmeOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose a file to upload or record a new one\n",
        "_upload requires 3rd-Party Cookies enabled in the browser_"
      ],
      "metadata": {
        "id": "ro_jgNOlOSHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(input_video_path):\n",
        "  print(\"found:\" + input_video_path)\n",
        "else: print(\"NOT FOUND!: \" + input_video_path)\n",
        "\n",
        "# work on live recording later\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "1XP2tp6NMjpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate normalized video file"
      ],
      "metadata": {
        "id": "ft4Dr5viVjwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_file_extension(input_file_path, new_extension):\n",
        "  filename, file_extension = os.path.splitext(input_file_path)\n",
        "  new_file_path = filename.split('.')[0] + new_extension\n",
        "\n",
        "  return new_file_path\n"
      ],
      "metadata": {
        "id": "R__z-oi2AyE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for running ffmpeg\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def execute_ffmpeg(command_string):\n",
        "  result = subprocess.Popen(command_string, stdout = subprocess.PIPE, stderr = subprocess.STDOUT, shell=True)\n",
        "  stdout, stderr = result.communicate()\n",
        "  \n",
        "  return (str(stdout))\n",
        "  "
      ],
      "metadata": {
        "id": "a11dpwL4IUON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_file(input_file_path, w, h):\n",
        "  print(\"generating normalized video\")\n",
        "\n",
        "  output_file_path = change_file_extension(input_file_path, \".normal.mp4\")\n",
        "\n",
        "  ffmpeg_cmd = \"ffmpeg -y -i \" \n",
        "  ffmpeg_cmd += input_file_path\n",
        "  ffmpeg_cmd += ' -c:v libx264 -vf \"scale=w=' + str(w) +':h=' + str(h)\n",
        "  ffmpeg_cmd += ':force_original_aspect_ratio=1, pad=' + str(w) + ':' + str(h) + ':(ow-iw)/2:(oh-ih)/2\" ' \n",
        "  ffmpeg_cmd += output_file_path\n",
        "  \n",
        "  success = execute_ffmpeg(ffmpeg_cmd)\n",
        "\n",
        "  print(output_file_path)\n",
        "\n",
        "  return output_file_path"
      ],
      "metadata": {
        "id": "7Jo2fnOH3Uij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_file_path = normalize_file(input_video_path, output_width, output_height)"
      ],
      "metadata": {
        "id": "lK6uf3fLAe7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate audio file"
      ],
      "metadata": {
        "id": "sP--7h5IVu1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_audio_file(input_file_path):\n",
        "  print(\"generating audio file\")\n",
        "\n",
        "  output_audio_file_path = change_file_extension(input_file_path, \".wav\")\n",
        "\n",
        "  ffmpeg_cmd = \"ffmpeg -y -i \" \n",
        "  ffmpeg_cmd += input_file_path\n",
        "  ffmpeg_cmd += ' -vn -ac 1 -ar 16k -acodec pcm_s16le '\n",
        "  ffmpeg_cmd += output_audio_file_path\n",
        "  \n",
        "  success = execute_ffmpeg(ffmpeg_cmd)\n",
        "  \n",
        "  print(output_audio_file_path)\n",
        "  \n",
        "  return output_audio_file_path"
      ],
      "metadata": {
        "id": "fD7HAu-9-XJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file_path = generate_audio_file(normal_file_path)"
      ],
      "metadata": {
        "id": "9w6_E8-CDNz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize audio file levels:\n",
        "\n",
        "https://bytesandbones.wordpress.com/2017/03/16/audio-nomalization-with-ffmpeg-using-loudnorm-ebur128-filter/"
      ],
      "metadata": {
        "id": "qdgjPDEiJTOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_substring(string_data, string_start, string_end):\n",
        "\n",
        "  string_data = str(string_data)\n",
        "  index_in = string_data.find(string_start)+len(string_start)\n",
        "  index_out = string_data.find(string_end)\n",
        "\n",
        "  substring = string_data[index_in:index_out]\n",
        "  remainder = string_data[index_out+len(string_end):]\n",
        "  \n",
        "  extracted_data = {'remainder': remainder, 'substring': substring.strip()}\n",
        "  return(remainder, substring.strip())"
      ],
      "metadata": {
        "id": "serJQ1ViRvsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_audio_file(input_file_path):\n",
        "\n",
        "  analysis_data = {}\n",
        "  print(\"analyzing audio from \" + input_file_path)\n",
        "\n",
        "  ffmpeg_analysis = 'ffmpeg -i '\n",
        "  ffmpeg_analysis += input_file_path\n",
        "  ffmpeg_analysis += ' -af loudnorm=I=-16:TP=-1.5:LRA=11:print_format=summary -f null -'\n",
        "\n",
        "  analysis_raw = execute_ffmpeg(ffmpeg_analysis)\n",
        "\n",
        "  # replace following with numbers from ffmpeg loudnorm stout:\n",
        "  # Input Integrated:    -47.5 LUFS\n",
        "  # Input True Peak:     -27.5 dBTP\n",
        "  # Input LRA:             8.9 LU\n",
        "  # Input Threshold:     -58.9 LUFS\n",
        "  \n",
        "  remaining_data, analysis_data['measured_int'] = extract_substring(analysis_raw, 'Input Integrated:', 'LUFS')\n",
        "  remaining_data, analysis_data['measured_itp'] = extract_substring(remaining_data, 'Input True Peak:', 'dBTP')\n",
        "  remaining_data, analysis_data['measured_lra'] = extract_substring(remaining_data, 'Input LRA:', 'LU')\n",
        "  remaining_data, analysis_data['measured_thresh'] = extract_substring(remaining_data, 'Input Threshold:', 'LUFS')\n",
        "  \n",
        "  # try some other scalars here?\n",
        "  analysis_data['offset'] = '-0.7'\n",
        "\n",
        "  return analysis_data"
      ],
      "metadata": {
        "id": "Bpi1_5QUyeM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_data = analyze_audio_file(audio_file_path)"
      ],
      "metadata": {
        "id": "gjRfehC47C1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`!ffmpeg -i /content/drive/MyDrive/DX451/Rules/honey/honey.wav -af loudnorm=I=-16:TP=-1.5:LRA=11:print_format=summary -f null -`"
      ],
      "metadata": {
        "id": "y6iha8mD4xYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_audio_file(input_file_path, analysis_data_dict):\n",
        "  print(\"Generating normalized audio from \" + input_file_path)\n",
        "\n",
        "  output_audio_file_path = change_file_extension(input_file_path, \".normal.wav\")\n",
        "  print(\"Normalized audio output: \" + output_audio_file_path)\n",
        "  \n",
        "  ffmpeg_adjustments = 'ffmpeg -y -i '\n",
        "  ffmpeg_adjustments += audio_file_path\n",
        "  ffmpeg_adjustments += ' -vn -ac 1 -ar 16k -acodec pcm_s16le'\n",
        "  ffmpeg_adjustments += ' -af loudnorm=I=-16:TP=-1.5:LRA=11:'\n",
        "  ffmpeg_adjustments += 'measured_I=' + analysis_data_dict['measured_int']\n",
        "  ffmpeg_adjustments += ':measured_TP=' + analysis_data_dict['measured_itp']\n",
        "  ffmpeg_adjustments += ':measured_LRA=' + analysis_data_dict['measured_lra']\n",
        "  ffmpeg_adjustments += ':measured_thresh=' + analysis_data_dict['measured_thresh']\n",
        "  ffmpeg_adjustments += ':offset=' + analysis_data_dict['offset']\n",
        "  ffmpeg_adjustments += ':linear=true:print_format=summary '\n",
        "  ffmpeg_adjustments += output_audio_file_path\n",
        "  \n",
        "  success = execute_ffmpeg(ffmpeg_adjustments)\n",
        "  \n",
        "  # print(output_audio_file_path)  \n",
        "  return output_audio_file_path"
      ],
      "metadata": {
        "id": "U7aIxCpfYUR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_audio_file_path = normalize_audio_file(audio_file_path, analysis_data)"
      ],
      "metadata": {
        "id": "GSoLd98rEet3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "apply normalized audio to video"
      ],
      "metadata": {
        "id": "BRKfVjxXa6by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_audio(input_video_path, input_audio_path):\n",
        "\n",
        "  output_video_path = change_file_extension(input_video_path, \".normal.audio.mp4\")\n",
        "\n",
        "  ffmpeg_cmd = \"ffmpeg -y -i \"\n",
        "  ffmpeg_cmd += input_video_path\n",
        "  ffmpeg_cmd += \" -i \"\n",
        "  ffmpeg_cmd += input_audio_path\n",
        "  ffmpeg_cmd += \" -c:v copy -map 0:v:0 -map 1:a:0 \"\n",
        "  ffmpeg_cmd += output_video_path\n",
        "\n",
        "  print(ffmpeg_cmd)\n",
        "\n",
        "  execute_ffmpeg(ffmpeg_cmd)\n",
        "\n",
        "  return output_video_path"
      ],
      "metadata": {
        "id": "by3hUamha44H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_video_audio_file_path = replace_audio(normal_file_path, normal_audio_file_path)"
      ],
      "metadata": {
        "id": "EmUeSYP4q_Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# convert audio to text"
      ],
      "metadata": {
        "id": "RQ0JqSvCkJUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a key file for communicating with Speech-to-text and cloud storage"
      ],
      "metadata": {
        "id": "p_egMeFy9SDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key_file_path = \"/content/drive/MyDrive/gcp-keys/\"\n",
        "service_account_keyfile = key_file_path + service_account_user_name + \".json\"\n",
        "\n",
        "if not os.path.isfile(service_account_keyfile):\n",
        "  print ( \"generating keyfile (limited number available, delete in console if necessary)\" )\n",
        "\n",
        "  # Authenticate project user\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "  # create keyfile\n",
        "  !gcloud config set project {project_id}\n",
        "  iam_account = service_account_user_name + \"@\" + project_id + \".iam.gserviceaccount.com\"\n",
        "  !gcloud iam service-accounts keys create {service_account_keyfile} --iam-account={iam_account}\n",
        "\n",
        "else:\n",
        "  print(\"keyfile found\")\n"
      ],
      "metadata": {
        "id": "UkIcjzv765au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the Google Cloud client libraries\n",
        "from google.cloud import speech\n",
        "\n",
        "## for reading and writing google cloud storage\n",
        "from google.cloud import storage\n",
        "\n",
        "# for processing \n",
        "import json\n",
        "\n",
        "# Instantiates clients\n",
        "speech_client = speech.SpeechClient.from_service_account_json(service_account_keyfile)\n",
        "storage_client = storage.Client.from_service_account_json(service_account_keyfile)"
      ],
      "metadata": {
        "id": "L2jzmOADipUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transfer file to gcs"
      ],
      "metadata": {
        "id": "MaGVCjb9mOUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_to_gcs(input_file_path):\n",
        "  gcs_audio_uri=\"gs://\" + bucket_name + \"/\" + content_name + \"/\"\n",
        "  !gsutil cp {input_file_path} {gcs_audio_uri}\n",
        "  gcs_audio_uri += os.path.basename(input_file_path)\n",
        "\n",
        "  return gcs_audio_uri"
      ],
      "metadata": {
        "id": "Vib3uUGHkHc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_audio_uri = upload_to_gcs(normal_audio_file_path)"
      ],
      "metadata": {
        "id": "MclSRESvn1I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## send async request to speech-to-text\n",
        " \n",
        "*   pass audio URI to STT\n",
        "*   get response\n",
        "*   convert to dict"
      ],
      "metadata": {
        "id": "RlnmsovDFbvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_text(gcs_audio_uri):\n",
        "  gcs_text_uri = change_file_extension(gcs_audio_uri, '.json')\n",
        "   \n",
        "  audio = speech.RecognitionAudio(\n",
        "    uri=gcs_audio_uri\n",
        "    )\n",
        "\n",
        "  config = speech.RecognitionConfig(\n",
        "      encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "      sample_rate_hertz=16000,\n",
        "      language_code=\"en-US\",\n",
        "      enable_word_time_offsets=True,\n",
        "      )\n",
        "\n",
        "  output_config = speech.TranscriptOutputConfig(\n",
        "      gcs_uri=gcs_text_uri\n",
        "      )\n",
        "\n",
        "  request = speech.LongRunningRecognizeRequest(\n",
        "      audio=audio, config=config, output_config=output_config\n",
        "      )\n",
        "\n",
        "  # asynchronous request\n",
        "  # https://cloud.google.com/speech-to-text/docs/basics?authuser=0#async-responses\n",
        "  # the asynchronous request will initiate a \n",
        "  # Long Running Operation (of type Operation) \n",
        "  # and return this operation to the callee immediately.\n",
        "\n",
        "  operation = speech_client.long_running_recognize(request=request)\n",
        "\n",
        "  print(\"Waiting for operation to complete...\")\n",
        "  result = operation.result(timeout=120)\n",
        "  print(\"Completed.\")\n",
        "\n",
        "  result_as_dict = json.loads(type(result).to_json(result))\n",
        "  \n",
        "  return result_as_dict\n"
      ],
      "metadata": {
        "id": "GEpqAtwGcYL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit request to Speech-to-Text"
      ],
      "metadata": {
        "id": "pNwn-uAewjDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_dict = convert_to_text(gcs_audio_uri)"
      ],
      "metadata": {
        "id": "akyMqK4Gweqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process text result"
      ],
      "metadata": {
        "id": "p6RTVI7mQBHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenate results"
      ],
      "metadata": {
        "id": "NVVfylmq0U2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from decimal import Decimal\n",
        "\n",
        "def remove_suffix(input_string, suffix):\n",
        "    if suffix and input_string.endswith(suffix):\n",
        "        return input_string[:-len(suffix)]\n",
        "    return input_string\n",
        "\n",
        "def convert_word(word):\n",
        "\n",
        "  start = round(Decimal(remove_suffix(word['startTime'],'s')),1)\n",
        "  end = round(Decimal(remove_suffix(word['endTime'],'s')),1)\n",
        "  dur = end - start\n",
        "\n",
        "  clean_word = {}\n",
        "  clean_word['word'] = word['word']\n",
        "  clean_word['start'] = str(start)\n",
        "  clean_word['duration'] = str(dur)\n",
        "\n",
        "  return clean_word"
      ],
      "metadata": {
        "id": "77P1XWYWP3VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_transcript = \"\"\n",
        "word_list = []\n",
        "\n",
        "# Each result is for a consecutive portion of the audio. Iterate through\n",
        "# them to get the transcripts for the entire audio file.\n",
        "\n",
        "# concatenate results\n",
        "for result in response_dict['results']:\n",
        "  full_transcript += result['alternatives'][0]['transcript'] + \" \"\n",
        "  for word in result['alternatives'][0]['words']:\n",
        "    word_list.append(convert_word(word))\n",
        "  \n",
        "print (\"transcript:\" + full_transcript)\n",
        "print(word_list)\n"
      ],
      "metadata": {
        "id": "wbYq7_NAKiCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sortfunc(word): \n",
        "  return word['word']\n",
        "\n",
        "# alphabetical_list = word_list.copy()\n",
        "# alphabetical_list.sort(key=sortfunc)"
      ],
      "metadata": {
        "id": "GkPRx827MUJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# apply captions"
      ],
      "metadata": {
        "id": "CayP1tEn5hTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_drawtext_cmd(word, fontpath):\n",
        "  drawtext_cmd = 'drawtext='\n",
        "  drawtext_cmd += 'fontcolor=white'\n",
        "  drawtext_cmd += ':box=1'\n",
        "  drawtext_cmd += ':boxcolor=black@0.5'\n",
        "  drawtext_cmd += ':boxborderw=5'\n",
        "  drawtext_cmd += ':fontsize=60'\n",
        "  drawtext_cmd += \":fontfile='\" + fontpath + \"'\"\n",
        "  drawtext_cmd += \":text='\" + word['word'] +\"'\"\n",
        "  drawtext_cmd += \":x=(w-text_w)/2:y=h-th-100\"\n",
        "  drawtext_cmd += \":enable='between(t,\" + str(word['start']) + \",\" + str(Decimal(word['start']) + Decimal(word['duration'])) + \")'\"\n",
        "\n",
        "  return drawtext_cmd\n"
      ],
      "metadata": {
        "id": "vK1-qzjUd8KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_overlay(input_video_path, fontpath, words):\n",
        "\n",
        "    output_video_path = change_file_extension(input_video_path, \".subt.mp4\")\n",
        "    ffmpeg_cmd = \"ffmpeg -y -i \" + input_video_path + ' -vf \"[in]'\n",
        "\n",
        "    # for word in words:\n",
        "    for i in range(len(words)):      \n",
        "      ffmpeg_cmd += get_drawtext_cmd(words[i], fontpath) \n",
        "      if i < (len(words)-1):\n",
        "        ffmpeg_cmd += \",\"\n",
        "    ffmpeg_cmd += '[out]\" '\n",
        "    ffmpeg_cmd += output_video_path\n",
        "\n",
        "    execute_ffmpeg(ffmpeg_cmd)\n",
        "    return (output_video_path)\n"
      ],
      "metadata": {
        "id": "7p9H-OS45neb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font_path = \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\"\n",
        "subtitled_video_path = text_overlay(normal_video_audio_file_path, font_path, word_list)\n"
      ],
      "metadata": {
        "id": "IHhPzn3O546_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze word list"
      ],
      "metadata": {
        "id": "D-zI0kpQ_mdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> lst = ['word', 'another', 'word', 'and', 'yet', 'another']\n",
        ">>> search = ['word', 'and', 'but']\n",
        ">>> [(w, lst.count(w)) for w in set(lst) if w in search]\n",
        "[('and', 1), ('word', 2)]"
      ],
      "metadata": {
        "id": "cgfbWY3YEipv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_list = []\n",
        "animal_list = []\n",
        "\n",
        "for word in word_list:\n",
        "  search_list.append(word['word'])\n",
        "\n",
        "with open('../animals.txt', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        animal_list.append(line.strip().lower())\n",
        "\n",
        "animal_matches = [(w, animal_list.count(w)) for w in set(animal_list) if w in search_list]\n",
        "\n",
        "for animal in animal_matches:\n",
        "  animal_words = list(filter(lambda item: item['word'] == animal, word_list))\n",
        "\n",
        "print (animal_words)\n",
        "\n"
      ],
      "metadata": {
        "id": "hZ1_BhtX_lvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# overlay images"
      ],
      "metadata": {
        "id": "yTTj3HFXIjBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "photo_overlay_video_path = change_file_extension(subtitled_video_path, \".photos.mp4\")\n",
        "\n",
        "ffmpeg_cmd = 'ffmpeg -y -i '\n",
        "ffmpeg_cmd += subtitled_video_path\n",
        "ffmpeg_cmd += ' -i bear.jpg '\n",
        "ffmpeg_cmd += '-i beaver.jpg '\n",
        "ffmpeg_cmd += '-i bird.jpg '\n",
        "ffmpeg_cmd += '-i badger.jpg '\n",
        "ffmpeg_cmd += '-filter_complex \"'\n",
        "ffmpeg_cmd += \"[0][1]overlay=enable='between(t,4.2,4.5)':x=(W-w)/2:y=(H-h)/2[out];\"\n",
        "ffmpeg_cmd += \"[out][2]overlay=enable='between(t,26.6,27.1)':x=(W-w)/2:y=(H-h)/2[out];\"\n",
        "ffmpeg_cmd += \"[out][3]overlay=enable='between(t,28.4,30)':x=(W-w)/2:y=(H-h)/2[out];\"\n",
        "ffmpeg_cmd += \"[out][4]overlay=enable='between(t,35.4,35.8)':x=(W-w)/2:y=(H-h)/2[out]\" \n",
        "ffmpeg_cmd += '\" -map [out] -map 0:a? '\n",
        "ffmpeg_cmd += photo_overlay_video_path\n",
        "\n",
        "print (ffmpeg_cmd)\n",
        "\n"
      ],
      "metadata": {
        "id": "_1HzgnxQXxPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -i /content/drive/MyDrive/DX451/Rules/honey/honey.subt.mp4 -i bear.jpg -i beaver.jpg -i bird.jpg -i badger.jpg -filter_complex \"[0][1]overlay=enable='between(t,4.2,4.5)':x=(W-w)/2:y=(H-h)/2[out];[out][2]overlay=enable='between(t,26.6,27.1)':x=(W-w)/2:y=(H-h)/2[out];[out][3]overlay=enable='between(t,28.4,30)':x=(W-w)/2:y=(H-h)/2[out];[out][4]overlay=enable='between(t,35.4,35.8)':x=(W-w)/2:y=(H-h)/2[out]\" -map [out] -map 0:a? /content/drive/MyDrive/DX451/Rules/honey/honey.photos.mp4"
      ],
      "metadata": {
        "id": "kcAUJZOdrIeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## overlay colors"
      ],
      "metadata": {
        "id": "j-tamv9Ymafh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -i honey.photos.mp4 -f lavfi -i \"color=brown:s=800x600\" -filter_complex \"blend=shortest=1:all_mode=overlay:all_opacity=0.7:enable='between(t,7.2,7.5)'\" honey.color.mp4"
      ],
      "metadata": {
        "id": "c0RyuwRen-nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -i honey.color.mp4 -f lavfi -i \"color=yellow:s=800x600\" -filter_complex \"blend=shortest=1:all_mode=overlay:all_opacity=0.7:enable='between(t,9.3,9.6)'\" honey.yellow.color.mp4"
      ],
      "metadata": {
        "id": "WpR1nz_tp4XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -i honey.yellow.color.mp4 -f lavfi -i \"color=blue:s=800x600\" -filter_complex \"blend=shortest=1:all_mode=overlay:all_opacity=0.7:enable='between(t,11.2,11.7)'\" honey.blue.color.mp4"
      ],
      "metadata": {
        "id": "ovXz9hlap3kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speed change\n",
        "\n",
        "TIME SHOULD BE LAST!! "
      ],
      "metadata": {
        "id": "1GL4BE1ctNzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_list)"
      ],
      "metadata": {
        "id": "Wo4ohSQ2IiLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "slow down clip"
      ],
      "metadata": {
        "id": "p_KKcNi81Rjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -ss 15.5 -t 2.5 -i honey.blue.color.mp4 -filter_complex \"[0:v]setpts=2.0*PTS[v];[0:a]atempo=0.5[a]\" -map \"[v]\" -map \"[a]\"  honey.slow-snip.mp4"
      ],
      "metadata": {
        "id": "yOHNXXPAs3pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recombine"
      ],
      "metadata": {
        "id": "21vsjB1r1O6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -t 15.5 -i honey.blue.color.mp4  -i honey.slow-snip.mp4 -ss 18.0 -i honey.blue.color.mp4 -filter_complex \"[0:0][0:1][1:0][1:1][2:0][2:1] concat=n=3:v=1:a=1[outv][outa]\" -map [outv] -map [outa] honey.timed.mp4"
      ],
      "metadata": {
        "id": "9shb_ZcI03cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rotate"
      ],
      "metadata": {
        "id": "GqDzC95z2mWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -i honey.timed.mp4 -filter_complex \"rotate=1:enable='between(t,19.5,21.5)'\" honey.rotated.mp4"
      ],
      "metadata": {
        "id": "1kxN3RDM17k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numbers"
      ],
      "metadata": {
        "id": "No-he1Q67Q1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i honey.rotated.mp4 -i honey.rotated.mp4 -i honey.rotated.mp4 -filter_complex \"[0:v][1:v][2:v]hstack=inputs=3[v]\" -map \"[v]\" honey.stacked.mp4"
      ],
      "metadata": {
        "id": "8QLlJhFX7QFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -t 23 -i honey.rotated.mp4 -ss 22 -t 1 -i honey.rotated.mp4 -ss 22 -i honey.rotated.mp4 -filter_complex \"[0:0][0:1][1:0][1:1][2:0][2:1] concat=n=3:v=1:a=1[outv][outa]\" -map [outv] -map [outa] honey.final.mp4"
      ],
      "metadata": {
        "id": "f1VLlVPf_SA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reassemble with ffmpeg"
      ],
      "metadata": {
        "id": "3_HpFTZnKgK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ffmpeg_input(file_name, word, easing):\n",
        "\n",
        "  padded_start = round(Decimal(word['start']) - Decimal(easing),2) \n",
        "  padded_duration = round(Decimal(word['duration']) + (2Decimal(easing),2) \n",
        "\n",
        "  ffmpeg_input = \" -ss \"\n",
        "  ffmpeg_input += str(padded_start)\n",
        "  ffmpeg_input += \" -t \"\n",
        "  ffmpeg_input += str(padded_duration)\n",
        "  ffmpeg_input += \" -i \"\n",
        "  ffmpeg_input += file_name\n",
        "\n",
        "  return (ffmpeg_input)\n",
        "\n",
        "def get_ffmpeg_filter(filter_list):\n",
        "  ffmpeg_filter = ' -filter_complex \"'\n",
        "\n",
        "  for x in range (len(filter_list)):\n",
        "     ffmpeg_filter += \"[\" + str(x) + \":0][\" + str(x) + \":1]\"\n",
        "\n",
        "  ffmpeg_filter += ' concat=n=' + str(len(filter_list)) + ':v=1:a=1 [v] [a]\"'\n",
        "  ffmpeg_filter += ' -map \"[v]\" -map \"[a]\" '  \n",
        "\n",
        "  return ffmpeg_filter  \n",
        "\n",
        "ffmpeg_cmd = \"ffmpeg -y\"\n",
        "\n",
        "for word in alphabetical_list:\n",
        "  ffmpeg_cmd += get_ffmpeg_input(normal_file_path, word, 0.1)\n",
        "\n",
        "ffmpeg_cmd += get_ffmpeg_filter(alphabetical_list)\n",
        "\n",
        "ffmpeg_cmd += output_file\n",
        "\n",
        "print(ffmpeg_cmd)\n",
        "\n",
        "for word in alphabetical_list:\n",
        "  print(word['word'])\n",
        "\n",
        "execute_ffmpeg(ffmpeg_cmd)\n",
        "\n",
        "# words.sort(key=get_word)\n",
        "\n",
        "# input_video = \"gold-watch.mp4\"\n",
        "# output_video = input_video.replace('.mp4', '-sorted.mp4')\n",
        "\n",
        "# ffmpeg_filter = \" -filter_complex \"\n",
        "\n",
        "# num_clips = 10\n",
        "\n",
        "# # for word in words:\n",
        "# for x in range(0, len(words)): \n",
        "#   ffmpeg_cmd = ffmpeg_cmd + get_ffmpeg_token(words[x])\n",
        "#   ffmpeg_filter = ffmpeg_filter + \"[\"+str(x)+\":0][\"+str(x)+\":1]\"\n",
        "\n",
        "\n",
        "\n",
        "# print (ffmpeg_cmd + ffmpeg_filter + '\"concat=n='+str(len(words))+':v=1:a=1[outv][outa]\" -map [outv] -map [outa] ' + output_video)\n"
      ],
      "metadata": {
        "id": "v50TksDjKm-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -ss 1.9 -t 0.1 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 7.0 -t 1.1 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 1.7 -t 0.2 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 3.3 -t 0.8 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 2.4 -t 0.9 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 2.0 -t 0.4 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 8.1 -t 0.6 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 5.2 -t 0.6 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 9.3 -t 0.6 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 1.2 -t 0.5 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 4.1 -t 1.1 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 8.7 -t 0.6 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -ss 5.8 -t 1.2 -i /content/drive/MyDrive/DX451/Rules/sample/sample.normal.mp4 -filter_complex \"[0:0][0:1][1:0][1:1][2:0][2:1][3:0][3:1][4:0][4:1][5:0][5:1][6:0][6:1][7:0][7:1][8:0][8:1][9:0][9:1][10:0][10:1][11:0][11:1][12:0][12:1] concat=n=13:v=1:a=1 [v] [a]\" -map \"[v]\" -map \"[a]\" /content/drive/MyDrive/DX451/Rules/sample/sample.output.mp4"
      ],
      "metadata": {
        "id": "s58ACCjVTeOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install Google-Images-Search"
      ],
      "metadata": {
        "id": "686abWh3LPt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gimages -k AIzaSyA6duw1XN3eB4jErhqQ4Bhzs_hwk3ktMxA -c wtkns-214817 search -q puppies -d / -w 500 -h 500"
      ],
      "metadata": {
        "id": "CifwFTmULwkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text-To-Speech"
      ],
      "metadata": {
        "id": "caWWD6L_J0Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "tts = gTTS(full_transcript)\n",
        "tts.save('honeyTTS.wav')\n",
        "sound_file = 'honeyTTS.wav'\n",
        "Audio(sound_file, autoplay=True)"
      ],
      "metadata": {
        "id": "MvY_FPTbZa2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio replacement"
      ],
      "metadata": {
        "id": "gqk7DeGfCLO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -i honey.final.mp4 -i honeyTTS.wav -filter_complex \"amix=inputs=2:duration=first:dropout_transition=3;[1]adelay=0|1500\" honey.mix.mp4"
      ],
      "metadata": {
        "id": "lqtmh1V2Ea6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y -i  honey.final.mp4 -i honeyTTS.wav -filter_complex \"[0:a]atrim=start=60,asetpts=PTS-STARTPTS[aud1];[1:a]atrim=0:60,afade=t=out:st=57:d=3,asetpts=PTS-STARTPTS[aud2];[aud2][aud1]concat=n=2:v=0:a=1[aout]\"  -map 0:v -map \"[aout]\" -c:v copy -c:a  honey.voice.mp4"
      ],
      "metadata": {
        "id": "AP5EQICwCKHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (text_to_speak)"
      ],
      "metadata": {
        "id": "1Wf9dKEEhqtW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}